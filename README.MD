# Multi-layer Perceptron

Multi-layer perceptron implementation from scratch developed in the Intelligent Systems course during the Master's Degree in Computer Science

## Proposed Activity

In the main notebook, we implement the logic of a multi-layer perceptron and evaluate its performance using toys datasets avaible at [sklearn](https://scikit-learn.org/stable/index.html)

## References

1. Weight Initialization
[What is Weight Initialization?](https://medium.com/@francescofranco_39234/what-is-weight-initialization-a58606f62513)
[Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a)

2. Feed-Foward
[Softmax function Explained Clearly and in Depth ｜Deep Learning fundamental](https://medium.com/@sue_nlp/what-is-the-softmax-function-used-in-deep-learning-illustrated-in-an-easy-to-understand-way-8b937fe13d49)

3. Loss
[Redes neurais artificiais #12: Funções de perda - parte 4](https://youtu.be/9Uw5KT6x4p0?si=pAGVzmu7_WDOeV-p)
[Função erro](https://ibb.co/qn7SFMP)

4. 